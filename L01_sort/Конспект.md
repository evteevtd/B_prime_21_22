## Оглавление
- Вступление + немного о себе 
- O — нотация, время и память
- Квадратичные сортировки
- Merge sort
- Quick sort
- Стабильность сортировок
- Count sort
	- radix sort
- Немного про std

## Вступление, О - нотация, время и память
Одну и ту же задачу можно решать разными способами, и как ни странно, нам очень бы хотелось для двух разных способов решения задачи каким-то образом сказать, какое из них "лучше".

Любой код в конечном счете превращается в набор инструкций для процессора, так что логичным выходом кажется запустить 2 разных программы на одном наборе данных и проверить, какая работает быстрее, но с этим есть очень много проблем: Время работы будет очень сильно зависеть от того, на каком именно устройстве мы запускаемся, при чем зависеть не очень простым и предсказуемым образом.

Однако есть и другой способ оценки, так называемые асимптотики. В чем идея? Для начала мы все уславливаемся с тем, что такое базовая операция, например сложение и умножение чисел, обрашение к память и так далее. Такие операции занимают 1 операцию.
Теперь пусть мы придумали какой-то алгоритм, который если дать ему на вход n чисел вычислит что-то, что нам нужно ровно за n операций. И другой алгоритм, которые получит тот же самый ответ, но проделав 2n операций. Для нас с этого момента эти алгоритмы в некотором смысле эквивалентны, и оба работают за O(n).
	
Более формально если какой-то алгоритм делает ровно f(n) операций, то время его работы можно оценить как O(g(n)), если существуют константы A и B, такие что f(n) <= A * G(n) + B для всех n.
	
Легко заметить, что это только оценка сверху, а именно n = O(n^2), так же существует оценка снизу (Омега) от n и ассимптотическое равенство (Тета) от n, но нам в первую очередь интересно оценивать время работы сверху.
	
Константу, которая при такой оценке всплывает в реальной жизни конечно же тоже нужно оценивать, но зачастую она играет менее важную роль.
Аналогично со временем работы нас безусловно будет интересовать и память, которая требуется программе на выполнение задачи, точное количество бит нам опять же не интересно, так что тут так же применима O — нотация.
	
// Можно тут потренероваться оценивать какие-то алгоритмы, но лучше мы пойдем дальше, и будем по дороге оценивать те, что нам встретятся.

## Квадратичные сортировки
Сегодня мы будем говорить о сортировках, и том, как немного модифицировав алгоритмы, которые мы будем использовать для сортировки массивов сделать ещё целую кучу интересных вещей.
	Небольшая оговорка: первое время мы будем считать, что очень мало что знаем о тех объектах, которые хотим отсортировать, единственное, что мы будем уметь делать, это взяв два элемента сказать, который из них меньше, а который больше.
	Сортировка вставками
	Сортировка выбором
	Сортировка пузырьком
Они все довольно скучные, потому что очень медленно работают О(n^2)
	Поговорим немного о быстрых сортировках.
	Сортировка слиянием
		Описание, время работы, кол-во инверсий, спойлеры на будущее
	Быстрая сортировка
		// стоит написать код //
		// можно ли честно оценить время работы?
		// почему её довольно часто используют?
		К-ая порядковая статистика на массиве
		// немного про детерминированную версию

	Большое разочарование состоит в том, в описанной модели сортировок быстрее, чем за время O(n*log(n)) не существует, и это довольно просто доказывается. Если останется время в конце лекции, можем этим заняться.

	Стабильные, нестабильные сортировки
	Ещё одним довольно важным свойством для алгоритма сортировки является то, что она будет делать в том случае, если в изначальном массиве есть 2 одинаковых элемента. Как вы помните, если сортировка считает 2 элемента одинаковыми, это не значит, что таковыми они и являются. Этот кусок я в своё время не понял, потом спустя довольно продожительное время пожалел, что не проникся сразу.
	Так вот сортировки бывают стабильными и не стабильными, первые сохраняют порядок элементов, вторые ничего не рарантируют.
	Разберёмся со всеми ранее разобранными (5 шт)


	А теперб впервые за долгое время вспомним, что довольно часто отсортировать нам нужно именно целые числа
	Сортировка подсчетом.
	Пусть дано n целых чисел, каждое от 0 до D - 1, оказываетс их можн оотсортировать за время О(n + D), для этого достаточно завести массив размера D, пройтись по числам и как бы сложить их в ячейки, то есть по сути для каждого чиста от 0 до D — 1 посчитать, сколько раз оно встречается в последовательности.
	Есть версия стабильной сортировки подсчётом, что это вообще может значить: пусть нам нужно отсортировать пары {int, smth}, по возрастанию int, а при равенстве int оставить элементы в том же порядке, что и в изначальном массиве: Здесь просто посчитать количество вхождений каждого int не достаточно, потому что к каждому прикреплён уникальный элемент.
	Плохим выходом будет завести vector<smth> d[D], хоть асимптотически будет что нужно, на практике это гораздо дольше. Так что мы поступим иначе:
Для начала посчитаем для каждого числа количество вхождений. Теперь заведём массив длины int ptr[D], в котором будут позиции начала для данного типа объектов (рисунок)
Теперб пройдемся по всему изначальному ммассиву и просто запихаем элементы на их место. 


// конец оригинальной программы
Теперь давайте научимся сортировать чиса за O(n + sqrt(D)) — представим число в виде пары из его первой и второй половины битов. Тогда отсортировать числа по возрастанию будет значить отсортировать такие пары лексикографически, то есть сначала по возрастанию первой половины, а при равенстве — второй половины. План такой, давайте сначала отсортируем все числа по возрастанию второй половины битов, а затем стабильно по возрастанию первой (рисунок). Работает за 2 * (N + sqrt(D)).

	К счастью писать сортировку вручную нужно довольно редко. На этом кантесте вам это сделать нужно, чтобы вы поняли принцыпы и научились такое писать, но на самом деле всё давным давно придумано и написано, в библиотеке есть как 
	std::sort() - hеализованная как introsort (гибридная сортировка quick + heap) или teamsort (quick + megre)
	std::stable_sort()












